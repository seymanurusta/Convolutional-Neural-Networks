{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# import necessary libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport cv2\nimport matplotlib.pyplot as plt\nimport os\nfrom keras.preprocessing.image import load_img, img_to_array\nfrom keras.models import Sequential\nfrom keras.layers import Convolution2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Flatten\nfrom keras.layers import Dense\nfrom numpy import asarray\nfrom PIL import Image\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.layers import Conv2D","execution_count":1,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#labelling data and reading images from the dataset(training dataset)\nfilenames = (os.listdir(\"../input/dogs-vs-cats/train/train/\"))\ny_train = []\nx_train = []\nfor i in filenames:\n    photo = load_img(\"../input/dogs-vs-cats/train/train/\"+i,target_size=(128,128))\n    photo = img_to_array(photo)\n    x_train.append(photo)\n    if 'cat' in i:\n        y_train.append(0)\n    else:\n        y_train.append(1)\nx_train = asarray(x_train)\ny_train = np.array(y_train)","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#count plot of ratio of number of cats vs dogs images\nimport seaborn as sns\nsns.countplot(x=pd.DataFrame(y_train)[0], data=pd.DataFrame(y_train))","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"<matplotlib.axes._subplots.AxesSubplot at 0x7f1ccd9ee710>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#labelling data and reading images from the dataset(test dataset)\nfilenames = (os.listdir(\"../input/cat-and-dog/test_set/test_set/cats/\"))\ny_test = []\nx_test = []\nfor i in filenames:\n    if i != '_DS_Store':\n        photo = load_img(\"../input/cat-and-dog/test_set/test_set/cats/\"+i,target_size=(128,128))\n        photo = img_to_array(photo)\n        x_test.append(photo)\n        if 'cat' in i:\n            y_test.append(0)\n        else:\n            y_test.append(1)\nfilenames = (os.listdir(\"../input/cat-and-dog/test_set/test_set/dogs/\"))\nfor i in filenames:\n    if i != '_DS_Store':\n        photo = load_img(\"../input/cat-and-dog/test_set/test_set/dogs/\"+i,target_size=(128,128))\n        photo = img_to_array(photo)\n        x_test.append(photo)\n        if 'cat' in i:\n            y_test.append(0)\n        else:\n            y_test.append(1)\nx_test = asarray(x_test)\ny_test = np.array(y_test)","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils import to_categorical\ny_train = to_categorical(y_train)\ny_test = to_categorical(y_test)","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(x_train.shape)\nprint(y_train.shape)","execution_count":7,"outputs":[{"output_type":"stream","text":"(25000, 128, 128, 3)\n(25000, 2)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3),activation='linear',input_shape=(128,128,3),padding='same'))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(MaxPooling2D((2, 2),padding='same'))\nmodel.add(Conv2D(64, (3, 3), activation='linear',padding='same'))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\nmodel.add(Conv2D(128, (3, 3), activation='linear',padding='same'))\nmodel.add(LeakyReLU(alpha=0.1))                  \nmodel.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='linear'))\nmodel.add(LeakyReLU(alpha=0.1))                  \nmodel.add(Dense(2, activation='softmax'))\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":9,"outputs":[{"output_type":"stream","text":"Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_1 (Conv2D)            (None, 128, 128, 32)      896       \n_________________________________________________________________\nleaky_re_lu_1 (LeakyReLU)    (None, 128, 128, 32)      0         \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 64, 64, 32)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 64, 64, 64)        18496     \n_________________________________________________________________\nleaky_re_lu_2 (LeakyReLU)    (None, 64, 64, 64)        0         \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 32, 32, 64)        0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 32, 32, 128)       73856     \n_________________________________________________________________\nleaky_re_lu_3 (LeakyReLU)    (None, 32, 32, 128)       0         \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 16, 16, 128)       0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 32768)             0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 128)               4194432   \n_________________________________________________________________\nleaky_re_lu_4 (LeakyReLU)    (None, 128)               0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 2)                 258       \n=================================================================\nTotal params: 4,287,938\nTrainable params: 4,287,938\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_train = model.fit(x_train, y_train, batch_size=64,epochs=20,verbose=1,validation_split=0.10)","execution_count":10,"outputs":[{"output_type":"stream","text":"Train on 22500 samples, validate on 2500 samples\nEpoch 1/20\n22500/22500 [==============================] - 16s 706us/step - loss: 6.7650 - accuracy: 0.6299 - val_loss: 0.5775 - val_accuracy: 0.7064\nEpoch 2/20\n22500/22500 [==============================] - 11s 503us/step - loss: 0.5400 - accuracy: 0.7315 - val_loss: 0.6263 - val_accuracy: 0.6956\nEpoch 3/20\n22500/22500 [==============================] - 11s 510us/step - loss: 0.4622 - accuracy: 0.7816 - val_loss: 0.5001 - val_accuracy: 0.7688\nEpoch 4/20\n22500/22500 [==============================] - 11s 493us/step - loss: 0.4053 - accuracy: 0.8142 - val_loss: 0.4968 - val_accuracy: 0.7796\nEpoch 5/20\n22500/22500 [==============================] - 11s 502us/step - loss: 0.3620 - accuracy: 0.8356 - val_loss: 0.4714 - val_accuracy: 0.7960\nEpoch 6/20\n22500/22500 [==============================] - 11s 496us/step - loss: 0.3115 - accuracy: 0.8651 - val_loss: 0.4685 - val_accuracy: 0.8040\nEpoch 7/20\n22500/22500 [==============================] - 12s 529us/step - loss: 0.2827 - accuracy: 0.8796 - val_loss: 0.4564 - val_accuracy: 0.8060\nEpoch 8/20\n22500/22500 [==============================] - 12s 514us/step - loss: 0.2382 - accuracy: 0.9016 - val_loss: 0.5160 - val_accuracy: 0.7904\nEpoch 9/20\n22500/22500 [==============================] - 12s 511us/step - loss: 0.2032 - accuracy: 0.9168 - val_loss: 0.9307 - val_accuracy: 0.7296\nEpoch 10/20\n22500/22500 [==============================] - 12s 511us/step - loss: 0.1905 - accuracy: 0.9212 - val_loss: 0.5691 - val_accuracy: 0.8060\nEpoch 11/20\n22500/22500 [==============================] - 12s 513us/step - loss: 0.1928 - accuracy: 0.9232 - val_loss: 0.6391 - val_accuracy: 0.7916\nEpoch 12/20\n22500/22500 [==============================] - 12s 527us/step - loss: 0.1812 - accuracy: 0.9292 - val_loss: 0.7595 - val_accuracy: 0.7896\nEpoch 13/20\n22500/22500 [==============================] - 11s 497us/step - loss: 0.1650 - accuracy: 0.9347 - val_loss: 0.7166 - val_accuracy: 0.8132\nEpoch 14/20\n22500/22500 [==============================] - 12s 514us/step - loss: 0.1769 - accuracy: 0.9323 - val_loss: 0.6750 - val_accuracy: 0.7924\nEpoch 15/20\n22500/22500 [==============================] - 11s 496us/step - loss: 0.1443 - accuracy: 0.9454 - val_loss: 0.7849 - val_accuracy: 0.8028\nEpoch 16/20\n22500/22500 [==============================] - 11s 496us/step - loss: 0.1386 - accuracy: 0.9479 - val_loss: 0.8240 - val_accuracy: 0.8068\nEpoch 17/20\n22500/22500 [==============================] - 12s 534us/step - loss: 0.1597 - accuracy: 0.9417 - val_loss: 0.7214 - val_accuracy: 0.8088\nEpoch 18/20\n22500/22500 [==============================] - 12s 514us/step - loss: 0.1262 - accuracy: 0.9529 - val_loss: 0.9815 - val_accuracy: 0.7788\nEpoch 19/20\n22500/22500 [==============================] - 11s 494us/step - loss: 0.1273 - accuracy: 0.9528 - val_loss: 0.8167 - val_accuracy: 0.8108\nEpoch 20/20\n22500/22500 [==============================] - 12s 512us/step - loss: 0.1356 - accuracy: 0.9491 - val_loss: 0.9690 - val_accuracy: 0.7904\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(x_train, y_train, batch_size=64,epochs=20,verbose=1,validation_split=0.20)","execution_count":13,"outputs":[{"output_type":"stream","text":"Train on 20000 samples, validate on 5000 samples\nEpoch 1/20\n20000/20000 [==============================] - 11s 530us/step - loss: 0.0957 - accuracy: 0.9656 - val_loss: 0.4718 - val_accuracy: 0.8950\nEpoch 2/20\n20000/20000 [==============================] - 11s 533us/step - loss: 0.0765 - accuracy: 0.9727 - val_loss: 0.6443 - val_accuracy: 0.8644\nEpoch 3/20\n20000/20000 [==============================] - 11s 547us/step - loss: 0.0859 - accuracy: 0.9697 - val_loss: 0.5882 - val_accuracy: 0.8728\nEpoch 4/20\n20000/20000 [==============================] - 11s 550us/step - loss: 0.0770 - accuracy: 0.9721 - val_loss: 0.5246 - val_accuracy: 0.8724\nEpoch 5/20\n20000/20000 [==============================] - 11s 546us/step - loss: 0.0710 - accuracy: 0.9747 - val_loss: 0.6162 - val_accuracy: 0.8718\nEpoch 6/20\n20000/20000 [==============================] - 10s 524us/step - loss: 0.0676 - accuracy: 0.9762 - val_loss: 0.5426 - val_accuracy: 0.8724\nEpoch 7/20\n20000/20000 [==============================] - 11s 526us/step - loss: 0.0847 - accuracy: 0.9696 - val_loss: 0.5453 - val_accuracy: 0.8784\nEpoch 8/20\n20000/20000 [==============================] - 11s 544us/step - loss: 0.0705 - accuracy: 0.9750 - val_loss: 0.6304 - val_accuracy: 0.8602\nEpoch 9/20\n20000/20000 [==============================] - 11s 569us/step - loss: 0.0714 - accuracy: 0.9765 - val_loss: 0.5662 - val_accuracy: 0.8738\nEpoch 10/20\n20000/20000 [==============================] - 11s 527us/step - loss: 0.0774 - accuracy: 0.9739 - val_loss: 0.5772 - val_accuracy: 0.8612\nEpoch 11/20\n20000/20000 [==============================] - 11s 530us/step - loss: 0.0755 - accuracy: 0.9739 - val_loss: 0.6750 - val_accuracy: 0.8694\nEpoch 12/20\n20000/20000 [==============================] - 11s 531us/step - loss: 0.0680 - accuracy: 0.9761 - val_loss: 0.7642 - val_accuracy: 0.8494\nEpoch 13/20\n20000/20000 [==============================] - 11s 530us/step - loss: 0.0944 - accuracy: 0.9687 - val_loss: 0.7355 - val_accuracy: 0.8518\nEpoch 14/20\n20000/20000 [==============================] - 11s 540us/step - loss: 0.0550 - accuracy: 0.9813 - val_loss: 0.8284 - val_accuracy: 0.8440\nEpoch 15/20\n20000/20000 [==============================] - 11s 544us/step - loss: 0.0573 - accuracy: 0.9826 - val_loss: 0.8332 - val_accuracy: 0.8590\nEpoch 16/20\n20000/20000 [==============================] - 11s 553us/step - loss: 0.0723 - accuracy: 0.9770 - val_loss: 0.7843 - val_accuracy: 0.8436\nEpoch 17/20\n20000/20000 [==============================] - 11s 540us/step - loss: 0.0845 - accuracy: 0.9739 - val_loss: 0.8766 - val_accuracy: 0.8386\nEpoch 18/20\n20000/20000 [==============================] - 11s 546us/step - loss: 0.0675 - accuracy: 0.9786 - val_loss: 0.9652 - val_accuracy: 0.8456\nEpoch 19/20\n20000/20000 [==============================] - 11s 542us/step - loss: 0.0877 - accuracy: 0.9738 - val_loss: 0.9091 - val_accuracy: 0.8386\nEpoch 20/20\n20000/20000 [==============================] - 11s 561us/step - loss: 0.0755 - accuracy: 0.9763 - val_loss: 0.8229 - val_accuracy: 0.8518\n","name":"stdout"},{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"<keras.callbacks.callbacks.History at 0x7f1cb4062ed0>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = model.predict(x_test, verbose=1)\n#model performance evaluation\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nprint(\"Accuracy score: \",accuracy_score(y_test, np.round_(preds)))\nprint(\"Classification report:\")\nprint(classification_report(y_test, np.round_(preds)))","execution_count":12,"outputs":[{"output_type":"stream","text":"2023/2023 [==============================] - 1s 254us/step\nAccuracy score:  0.9278299555116164\nClassification report:\n              precision    recall  f1-score   support\n\n           0       0.88      0.99      0.93      1011\n           1       0.98      0.87      0.92      1012\n\n   micro avg       0.93      0.93      0.93      2023\n   macro avg       0.93      0.93      0.93      2023\nweighted avg       0.93      0.93      0.93      2023\n samples avg       0.93      0.93      0.93      2023\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = model.predict(x_test, verbose=1)\n#model performance evaluation\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nprint(\"Accuracy score: \",accuracy_score(y_test, np.round_(preds)))\nprint(\"Classification report:\")\nprint(classification_report(y_test, np.round_(preds)))","execution_count":14,"outputs":[{"output_type":"stream","text":"2023/2023 [==============================] - 0s 241us/step\nAccuracy score:  0.9653979238754326\nClassification report:\n              precision    recall  f1-score   support\n\n           0       0.97      0.97      0.97      1011\n           1       0.97      0.97      0.97      1012\n\n   micro avg       0.97      0.97      0.97      2023\n   macro avg       0.97      0.97      0.97      2023\nweighted avg       0.97      0.97      0.97      2023\n samples avg       0.97      0.97      0.97      2023\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = model.predict(x_train, verbose=1)\n#model performance evaluation\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nprint(\"Accuracy score: \",accuracy_score(y_train, np.round_(preds)))\nprint(\"Classification report:\")\nprint(classification_report(y_train, np.round_(preds)))","execution_count":17,"outputs":[{"output_type":"stream","text":"25000/25000 [==============================] - 6s 227us/step\nAccuracy score:  0.95904\nClassification report:\n              precision    recall  f1-score   support\n\n           0       0.96      0.96      0.96     12500\n           1       0.96      0.96      0.96     12500\n\n   micro avg       0.96      0.96      0.96     25000\n   macro avg       0.96      0.96      0.96     25000\nweighted avg       0.96      0.96      0.96     25000\n samples avg       0.96      0.96      0.96     25000\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}